{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPAug imported successfully\n",
      "Torch version: 2.5.1+cu121\n",
      "Transformers version: 4.48.1\n",
      "CUDA available: True\n",
      "Current device: NVIDIA GeForce RTX 4080 SUPER\n",
      "cuda\n",
      "Original reviews: 500\n",
      "Augmented reviews: 1362\n",
      "Total reviews: 1862\n",
      "\n",
      "Example augmentations:\n",
      "\n",
      "Original: Outstanding performance.\n",
      "Augmented: not what i originally expected at all.\n",
      "\n",
      "Original: Honestly, It's the best I've ever used.\n",
      "Augmented: fortunately, great customer service.\n",
      "\n",
      "Original: Honestly, Exactly what I was looking for.\n",
      "Augmented: Honestly, This is amazing!\n"
     ]
    }
   ],
   "source": [
    "# Category 1, Dataset Preparation \n",
    "\n",
    "# 1. Synthetic Dataset Creation and Augmentation \n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import nlpaug.augmenter.word as naw\n",
    "import torch\n",
    "print(\"NLPAug imported successfully\")\n",
    "import random\n",
    "\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Current device: {torch.cuda.get_device_name(0)}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# Sample positive and negative reviews\n",
    "positive_reviews = [\n",
    "    \"This product is amazing!\",\n",
    "    \"I highly recommend this.\",\n",
    "    \"It's the best I've ever used.\",\n",
    "    \"Excellent quality and value.\",\n",
    "    \"Five stars!\",\n",
    "    \"Great customer service.\",\n",
    "    \"Exactly what I was looking for.\",\n",
    "    \"Very satisfied with my purchase.\",\n",
    "    \"Outstanding performance.\",\n",
    "    \"Worth every penny!\"\n",
    "]\n",
    "\n",
    "negative_reviews = [\n",
    "    \"This product is terrible.\",\n",
    "    \"I would not recommend this.\",\n",
    "    \"It's the worst I've ever used.\",\n",
    "    \"Poor quality and overpriced.\",\n",
    "    \"One star!\",\n",
    "    \"Horrible customer service.\",\n",
    "    \"Not what I expected at all.\",\n",
    "    \"Very disappointed with my purchase.\",\n",
    "    \"Unreliable performance.\",\n",
    "    \"Complete waste of money!\"\n",
    "]\n",
    "\n",
    "# Generate 500 base sentences by repeating and slightly modifying the samples\n",
    "all_reviews = []\n",
    "for i in range(250):\n",
    "    # Add some random variation to avoid exact duplicates\n",
    "    pos_review = positive_reviews[i % len(positive_reviews)]\n",
    "    neg_review = negative_reviews[i % len(negative_reviews)]\n",
    "\n",
    "    # Add simple variations to make the dataset more diverse\n",
    "    if random.random() > 0.5:\n",
    "        pos_review = \"Honestly, \" + pos_review\n",
    "    if random.random() > 0.5:\n",
    "        neg_review = \"Unfortunately, \" + neg_review\n",
    "\n",
    "    all_reviews.append(pos_review)\n",
    "    all_reviews.append(neg_review)\n",
    "\n",
    "# Initialize augmenters\n",
    "aug_insert = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased',\n",
    "    action=\"insert\",\n",
    "    aug_p=0.1  # Probability of augmenting each word\n",
    ")\n",
    "\n",
    "aug_sub = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased',\n",
    "    action=\"substitute\",\n",
    "    aug_p=0.1,\n",
    "    stopwords=['not', 'no', 'never']  # Prevent changing sentiment-critical words\n",
    ")\n",
    "\n",
    "\n",
    "# Augment the dataset\n",
    "augmented_reviews = []\n",
    "for review in all_reviews:\n",
    "    try:\n",
    "        # Insert words\n",
    "        aug_text = aug_insert.augment(review)[0]\n",
    "        augmented_reviews.append(aug_text)\n",
    "\n",
    "        # Substitute words\n",
    "        aug_text = aug_sub.augment(review)[0]\n",
    "        augmented_reviews.append(aug_text)\n",
    "\n",
    "        # Simple word deletion (manual approach)\n",
    "        words = review.split()\n",
    "        if len(words) > 3:  # Only delete if we have enough words\n",
    "            del_idx = random.randint(0, len(words)-1)\n",
    "            words.pop(del_idx)\n",
    "            aug_text = \" \".join(words)\n",
    "            augmented_reviews.append(aug_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error augmenting review: {review}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Combine original and augmented reviews\n",
    "final_reviews = all_reviews + augmented_reviews\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Original reviews: {len(all_reviews)}\")\n",
    "print(f\"Augmented reviews: {len(augmented_reviews)}\")\n",
    "print(f\"Total reviews: {len(final_reviews)}\")\n",
    "\n",
    "# Print some examples\n",
    "print(\"\\nExample augmentations:\")\n",
    "for i in range(3):\n",
    "    orig_idx = random.randint(0, len(all_reviews)-1)\n",
    "    aug_idx = random.randint(0, len(augmented_reviews)-1)\n",
    "    print(f\"\\nOriginal: {all_reviews[orig_idx]}\")\n",
    "    print(f\"Augmented: {augmented_reviews[aug_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:07<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total reviews: 1867\n",
      "Gaps created: 186\n",
      "\n",
      "Reconstruction Examples:\n",
      "Reconstructed: a total  this product is just terrible. this product screams terrible.\n",
      "Reconstructed: review poor work and overpriced. Poor and over priced.\n",
      "Reconstructed: this product line is terrible. this product appeared terrible.  honestly, i personally recommend this.\n",
      "Reconstructed: Sadly, Very disappointed with my purchase.  Unfortunately, Unreliable performance.\n",
      "Reconstructed: a complete  Unfortunately, Not what I expected at all.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Handling Missing Values\n",
    "\n",
    "\n",
    "from transformers import pipeline\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ReviewReconstructor:\n",
    "    def __init__(self, device=None):\n",
    "        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.generator = self._create_generator()\n",
    "        # Sentiment keywords for better context understanding\n",
    "        self.positive_keywords = {'amazing', 'recommend', 'best', 'excellent', 'stars', 'great', \n",
    "                                'exactly', 'satisfied', 'outstanding', 'worth'}\n",
    "        self.negative_keywords = {'terrible', 'not', 'worst', 'poor', 'horrible', 'disappointed', \n",
    "                                'unreliable', 'waste', 'unfortunately'}\n",
    "\n",
    "    def _create_generator(self):\n",
    "        return pipeline(\n",
    "            \"text2text-generation\",\n",
    "            model=\"t5-base\",\n",
    "            device=0 if self.device == 'cuda' else -1,\n",
    "            clean_up_tokenization_spaces=True\n",
    "        )\n",
    "\n",
    "    def _detect_sentiment(self, text):\n",
    "        \"\"\"Detect sentiment based on keyword presence.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        pos_count = sum(1 for word in self.positive_keywords if word in text_lower)\n",
    "        neg_count = sum(1 for word in self.negative_keywords if word in text_lower)\n",
    "        return 'positive' if pos_count > neg_count else 'negative'\n",
    "\n",
    "    def _get_context(self, text_list, current_idx):\n",
    "        # Get surrounding context\n",
    "        prev_texts = [t for t in text_list[max(0, current_idx - 2):current_idx] if t.strip()]\n",
    "        next_texts = [t for t in text_list[current_idx + 1:current_idx + 3] if t.strip()]\n",
    "        \n",
    "        # Combine context\n",
    "        context_text = \" \".join(prev_texts + next_texts)\n",
    "        sentiment = self._detect_sentiment(context_text)\n",
    "        \n",
    "        # Format prompt with sentiment guidance\n",
    "        prompt = f\"complete {sentiment} review:\"\n",
    "        if prev_texts:\n",
    "            prompt += f\" {' '.join(prev_texts)}\"\n",
    "        prompt += \" [MISSING]\"\n",
    "        if next_texts:\n",
    "            prompt += f\" {' '.join(next_texts)}\"\n",
    "            \n",
    "        return prompt, sentiment\n",
    "\n",
    "    def _clean_generated_text(self, text, sentiment):\n",
    "        \"\"\"Clean and validate generated text.\"\"\"\n",
    "        # Remove common prefix artifacts\n",
    "        artifacts = [\n",
    "            \"review::\", \"negative review:\", \"complete positive review:\",\n",
    "            \"complete negative review:\", \"positive review:\", \"complete review:\", \":\", \"True\"\n",
    "        ]\n",
    "        for artifact in artifacts:\n",
    "            text = text.replace(artifact, \"\").strip()\n",
    "\n",
    "        # Remove [MISSING] placeholders\n",
    "        text = text.replace(\"[MISSING]\", \"\").strip()\n",
    "\n",
    "        # Ensure proper sentence structure\n",
    "        if len(text.split()) < 3:\n",
    "            text = \"This product is excellent!\" if sentiment == 'positive' else \"This product is disappointing.\"\n",
    "\n",
    "        # Ensure proper ending punctuation\n",
    "        if not any(text.endswith(char) for char in \".!?\"):\n",
    "            text += \".\"\n",
    "\n",
    "        return text\n",
    "\n",
    "    def reconstruct_texts(self, reviews, missing_indices, batch_size=32):\n",
    "        \"\"\"Reconstruct missing texts with batched processing.\"\"\"\n",
    "        reconstructed = reviews.copy()\n",
    "\n",
    "        # Process in batches\n",
    "        for i in tqdm(range(0, len(missing_indices), batch_size)):\n",
    "            batch_indices = missing_indices[i:i + batch_size]\n",
    "            prompts = []\n",
    "            sentiments = []\n",
    "            \n",
    "            # Prepare batch\n",
    "            for idx in batch_indices:\n",
    "                prompt, sentiment = self._get_context(reviews, idx)\n",
    "                prompts.append(prompt)\n",
    "                sentiments.append(sentiment)\n",
    "            \n",
    "            # Generate texts\n",
    "            generated = self.generator(\n",
    "                prompts,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_p=0.7,\n",
    "                top_k=25,\n",
    "                repetition_penalty=1.4,\n",
    "                num_return_sequences=1,\n",
    "                no_repeat_ngram_size=3,\n",
    "                max_length=50,\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "            \n",
    "            # Process generated texts\n",
    "            for idx, gen, sentiment in zip(batch_indices, generated, sentiments):\n",
    "                # The generated output is already a dictionary with 'generated_text' key\n",
    "                text = gen['generated_text']  # Removed the [0] indexing\n",
    "                cleaned_text = self._clean_generated_text(text, sentiment)\n",
    "                reconstructed[idx] = cleaned_text\n",
    "            \n",
    "        return reconstructed\n",
    "\n",
    "# Initialize reconstructor\n",
    "reconstructor = ReviewReconstructor()\n",
    "missing_percentage=0.1\n",
    "\n",
    "# Create gaps\n",
    "num_missing = int(len(final_reviews) * missing_percentage)\n",
    "missing_indices = random.sample(range(len(final_reviews)), num_missing)\n",
    "reviews_with_gaps = final_reviews.copy()\n",
    "\n",
    "for idx in missing_indices:\n",
    "    reviews_with_gaps[idx] = \"\"\n",
    "\n",
    "# Reconstruct\n",
    "reconstructed = reconstructor.reconstruct_texts(reviews_with_gaps, missing_indices)\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nTotal reviews: {len(final_reviews)}\")\n",
    "print(f\"Gaps created: {num_missing}\")\n",
    "print(\"\\nReconstruction Examples:\")\n",
    "\n",
    "# Show some examples\n",
    "sample_size = min(5, len(missing_indices))\n",
    "for idx in random.sample(missing_indices, sample_size):\n",
    "    print(f\"Reconstructed: {reconstructed[idx]}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      4961\n",
      "           1       0.89      0.91      0.90      5039\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.89      0.89     10000\n",
      "weighted avg       0.90      0.90      0.89     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40000/40000 [00:24<00:00, 1653.68 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:05<00:00, 1672.08 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.44105073331296446\n",
      "\n",
      "TinyBERT Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86      4961\n",
      "           1       0.85      0.90      0.87      5039\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Kaggle Dataset Preprocessing \n",
    "\n",
    "# Install required packages\n",
    "#!pip install kaggle transformers scikit-learn pandas numpy\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "# Configure Kaggle API (you'll need to upload your kaggle.json)\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = '/content'\n",
    "\n",
    "# Download IMDB dataset\n",
    "#!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "\n",
    "# Extract dataset\n",
    "#!unzip imdb-dataset-of-50k-movie-reviews.zip\n",
    "\n",
    "# Load and preprocess data\n",
    "#df = pd.read_csv('IMDB Dataset.csv')\n",
    "df = pd.read_csv('C:/Users/Kone/Downloads/archive/IMDB Dataset.csv')\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['review'].values, \n",
    "    df['sentiment'].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "# Baseline Model (Logistic Regression)\n",
    "# Tokenize with basic approach\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train logistic regression\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "lr_preds = lr_model.predict(X_test_tfidf)\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "print(classification_report(y_test, lr_preds))\n",
    "\n",
    "# Transformer Model (TinyBERT)\n",
    "# Prepare datasets\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'text': X_train,\n",
    "    'label': y_train\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    'text': X_test,\n",
    "    'label': y_test\n",
    "})\n",
    "\n",
    "# Tokenize datasets\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda x: tokenizer(x['text'], padding=True, truncation=True),\n",
    "    batched=True\n",
    ")\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda x: tokenizer(x['text'], padding=True, truncation=True),\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "# Load TinyBERT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'prajjwal1/bert-tiny',\n",
    "    num_labels=2\n",
    ")\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 1\n",
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        \n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "bert_preds = np.array(predictions)\n",
    "print(\"\\nTinyBERT Results:\")\n",
    "print(classification_report(true_labels, bert_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing standard tokenizers:\n",
      "  Tokenizer                                             Tokens  Num_Tokens  \\\n",
      "0      BERT  [the, quick, brown, fox, jumps, over, the, laz...          22   \n",
      "1      GPT2  [The, Ä quick, Ä brown, Ä fox, Ä jumps, Ä over, Ä th...          20   \n",
      "2   RoBERTa  [The, Ä quick, Ä brown, Ä fox, Ä jumps, Ä over, Ä th...          20   \n",
      "\n",
      "   Vocabulary_Size  \n",
      "0            30522  \n",
      "1            50257  \n",
      "2            50265  \n",
      "\n",
      "Training custom tokenizer...\n",
      "\n",
      "Testing custom tokenizer:\n",
      "{'Original': \"This is a test of our custom tokenizer! Let's see how it performs.\", 'Encoded_IDs': [417, 162, 120, 3288, 146, 1427, 6741, 6900, 9325, 5], 'Decoded': \"Ä This Ä is Ä a Ä test Ä of Ä our Ä custom Ä token izer ! Ä Let 's Ä see Ä how Ä it Ä performs .\", 'Num_Tokens': 17}\n"
     ]
    }
   ],
   "source": [
    "# Category 2: Tokenization\n",
    "\n",
    "# Install required packages\n",
    "#!pip install transformers tokenizers datasets\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers, processors\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# 4. Tokenizer Comparison\n",
    "def compare_tokenizers():\n",
    "    # Initialize tokenizers\n",
    "    tokenizers = {\n",
    "        'BERT': AutoTokenizer.from_pretrained('bert-base-uncased'),\n",
    "        'GPT2': AutoTokenizer.from_pretrained('gpt2'),\n",
    "        'RoBERTa': AutoTokenizer.from_pretrained('roberta-base')\n",
    "    }\n",
    "    \n",
    "    # Sample text for comparison\n",
    "    text = \"The quick brown fox jumps over the lazy dog! Let's see how different tokenizers handle this.\"\n",
    "    \n",
    "    results = []\n",
    "    for name, tokenizer in tokenizers.items():\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        results.append({\n",
    "            'Tokenizer': name,\n",
    "            'Tokens': tokens,\n",
    "            'Num_Tokens': len(tokens),\n",
    "            'Vocabulary_Size': tokenizer.vocab_size\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 5. Custom Tokenizer Training \n",
    "def train_custom_tokenizer():\n",
    "    # Load a small dataset for training\n",
    "    dataset = load_dataset(\"imdb\", split=\"train[:1000]\")\n",
    "    \n",
    "    # Initialize a new tokenizer (BPE model)\n",
    "    tokenizer = Tokenizer(models.BPE())\n",
    "    \n",
    "    # Set up pre-tokenizer\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=True)\n",
    "    \n",
    "    # Prepare training\n",
    "    trainer = trainers.BpeTrainer(\n",
    "        vocab_size=25000,\n",
    "        special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "    )\n",
    "    \n",
    "    # Create iterator of texts for training\n",
    "    def batch_iterator():\n",
    "        batch_size = 1000\n",
    "        for i in range(0, len(dataset), batch_size):\n",
    "            yield dataset[i:i + batch_size][\"text\"]\n",
    "    \n",
    "    # Train tokenizer\n",
    "    tokenizer.train_from_iterator(batch_iterator(), trainer=trainer)\n",
    "    \n",
    "    # Save tokenizer\n",
    "    tokenizer.save(\"custom_tokenizer.json\")\n",
    "    \n",
    "    return tokenizer\n",
    "\n",
    "# Test Custom Tokenizer\n",
    "def test_tokenizers(custom_tokenizer):\n",
    "    # Test text\n",
    "    test_text = \"This is a test of our custom tokenizer! Let's see how it performs.\"\n",
    "    \n",
    "    # Load saved custom tokenizer\n",
    "    custom_tokenizer = Tokenizer.from_file(\"custom_tokenizer.json\")\n",
    "    \n",
    "    # Encode and decode\n",
    "    encoded = custom_tokenizer.encode(test_text)\n",
    "    decoded = custom_tokenizer.decode(encoded.ids)\n",
    "    \n",
    "    return {\n",
    "        'Original': test_text,\n",
    "        'Encoded_IDs': encoded.ids[:10],  # First 10 tokens\n",
    "        'Decoded': decoded,\n",
    "        'Num_Tokens': len(encoded.ids)\n",
    "    }\n",
    "\n",
    "# Run comparisons\n",
    "print(\"Comparing standard tokenizers:\")\n",
    "comparison_df = compare_tokenizers()\n",
    "print(comparison_df)\n",
    "\n",
    "print(\"\\nTraining custom tokenizer...\")\n",
    "custom_tokenizer = train_custom_tokenizer()\n",
    "\n",
    "print(\"\\nTesting custom tokenizer:\")\n",
    "test_results = test_tokenizers(custom_tokenizer)\n",
    "print(test_results)\n",
    "\n",
    "# Optional: Save custom tokenizer for reuse\n",
    "#custom_tokenizer.save_pretrained(\"./custom_tokenizer\") todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category 3: Pre-trained Models \n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    BlipProcessor, \n",
    "    BlipForConditionalGeneration\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_length=512):\n",
    "        self.encodings = tokenizer(\n",
    "            dataset[\"text\" if \"text\" in dataset.features else \"sms\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        self.labels = torch.tensor(dataset[\"label\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n",
    "            \"labels\": self.labels[idx]\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs, device, learning_rate=2e-5):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    model.to(device)\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "                \n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                \n",
    "                val_loss += outputs.loss.item()\n",
    "                predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "                correct += (predictions == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        accuracy = correct / total\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss = {total_loss/len(train_loader):.4f}, \"\n",
    "              f\"Val Loss = {val_loss/len(val_loader):.4f}, \"\n",
    "              f\"Val Accuracy = {accuracy:.4f}\")\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), f\"best_model_epoch_{epoch+1}.pt\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_distilbert():\n",
    "    dataset = load_dataset(\"imdb\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\",\n",
    "        num_labels=2\n",
    "    )\n",
    "    \n",
    "    train_dataset = TextDataset(dataset[\"train\"], tokenizer)\n",
    "    val_dataset = TextDataset(dataset[\"test\"], tokenizer)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = train_model(model, train_loader, val_loader, num_epochs=3, device=device)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "def train_bert_spam():\n",
    "    dataset = load_dataset(\"sms_spam\")\n",
    "    split_dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-uncased\",\n",
    "        num_labels=2\n",
    "    )\n",
    "    \n",
    "    train_dataset = TextDataset(split_dataset[\"train\"], tokenizer)\n",
    "    val_dataset = TextDataset(split_dataset[\"test\"], tokenizer)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = train_model(model, train_loader, val_loader, num_epochs=1, device=device)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "def setup_blip_captioning():\n",
    "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "    \n",
    "    def generate_caption(image_path, processor, model):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "        \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        inputs = processor(images=image, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs)\n",
    "        caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        return caption\n",
    "    \n",
    "    def translate_caption(caption):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        translator = AutoModelForSeq2SeqLM.from_pretrained(f\"Helsinki-NLP/opus-mt-tc-big-en-fi\")\n",
    "        translator_tokenizer = AutoTokenizer.from_pretrained(f\"Helsinki-NLP/opus-mt-tc-big-en-fi\")\n",
    "        \n",
    "        translator.to(device)\n",
    "        inputs = translator_tokenizer(caption, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = translator.generate(**inputs)\n",
    "        translation = translator_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        return translation\n",
    "    \n",
    "    return processor, model, generate_caption, translate_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DistilBERT for sentiment analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1563/1563 [03:11<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.2523, Val Loss = 0.2294, Val Accuracy = 0.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1563/1563 [03:12<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.1404, Val Loss = 0.2250, Val Accuracy = 0.9210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1563/1563 [03:11<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.0716, Val Loss = 0.2275, Val Accuracy = 0.9295\n"
     ]
    }
   ],
   "source": [
    "print(\"Training DistilBERT for sentiment analysis...\")\n",
    "distilbert_model, distilbert_tokenizer = train_distilbert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training BERT for spam classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1/1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:07<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.0768, Val Loss = 0.0499, Val Accuracy = 0.9883\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining BERT for spam classification...\")\n",
    "bert_model, bert_tokenizer = train_bert_spam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up BLIP for image captioning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Kone\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-tc-big-en-fi. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: image-1.jpg\n",
      "Caption: a bowl of oranges with a half of a grape\n",
      "Translation: kulhollinen appelsiineja, joissa on puolikas rypÃ¤lettÃ¤\n",
      "\n",
      "Image: image-2.jpg\n",
      "Caption: the tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori\n",
      "Translation: tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori tori\n",
      "\n",
      "Image: image-3.jpg\n",
      "Caption: a fluffy orange cat with a white face\n",
      "Translation: pÃ¶rrÃ¶inen oranssi kissa, jolla on valkoiset kasvot\n",
      "\n",
      "Image: image-4.jpg\n",
      "Caption: the old bridge in mostar, bosnia\n",
      "Translation: Mostarissa sijaitseva vanha silta, bosnia\n",
      "\n",
      "Image: image-5.jpg\n",
      "Caption: a river with trees and bushes in the background\n",
      "Translation: joki, jonka taustalla on puita ja pensaita\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSetting up BLIP for image captioning...\")\n",
    "blip_processor, blip_model, caption_fn, translate_fn = setup_blip_captioning()\n",
    "\n",
    "\n",
    "\n",
    "# Test BLIP with sample images\n",
    "sample_images = [\"image-1.jpg\", \"image-2.jpg\", \"image-3.jpg\", \"image-4.jpg\", \"image-5.jpg\"]\n",
    "for img_path in sample_images:\n",
    "    try:\n",
    "        caption = caption_fn(img_path, blip_processor, blip_model)\n",
    "        translation = translate_fn(caption)\n",
    "        print(f\"\\nImage: {img_path}\")\n",
    "        print(f\"Caption: {caption}\")\n",
    "        print(f\"Translation: {translation}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image {img_path} not found. Please provide valid image paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 13:43:54,067\tINFO worker.py:1841 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'CPU': 16.0, 'memory': 10202755892.0, 'node:127.0.0.1': 1.0, 'object_store_memory': 5101377945.0, 'GPU': 1.0}\n",
      "True\n",
      "Starting hyperparameter optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "2025-02-02 13:44:02,331\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-02-02 13:44:03 (running for 00:00:00.82)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 1.0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: C:/Users/Kone/AppData/Local/Temp/ray/session_2025-02-02_13-43-52_377343_24792/artifacts/2025-02-02_13-44-02/tune_bert/driver_artifacts\n",
      "Number of trials: 20/20 (20 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-02-02 13:44:08 (running for 00:00:05.84)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 1.0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: C:/Users/Kone/AppData/Local/Temp/ray/session_2025-02-02_13-43-52_377343_24792/artifacts/2025-02-02_13-44-02/tune_bert/driver_artifacts\n",
      "Number of trials: 20/20 (20 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_func pid=25824)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[36m(train_func pid=25824)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[36m(train_func pid=25824)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[36m(train_func pid=25824)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/4689 [00:00<?, ?it/s]\n",
      "2025-02-02 13:44:11,126\tERROR tune_controller.py:1331 -- Trial task failed for trial train_func_ff99a_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2772, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\_private\\worker.py\", line 919, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=25824, ip=127.0.0.1, actor_id=1504e6d7334aee1d6210ecb701000000, repr=train_func)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\air\\_internal\\util.py\", line 107, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 44, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 249, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"C:\\Users\\Kone\\AppData\\Local\\Temp\\ipykernel_24792\\1460561625.py\", line 118, in train_func\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\transformers\\trainer.py\", line 2171, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\transformers\\trainer.py\", line 2531, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\transformers\\trainer.py\", line 3675, in training_step\n",
      "    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\transformers\\trainer.py\", line 3752, in compute_loss\n",
      "    raise ValueError(\n",
      "ValueError: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,token_type_ids,attention_mask.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "== Status ==\n",
      "Current time: 2025-02-02 13:44:13 (running for 00:00:10.88)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 1.0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: C:/Users/Kone/AppData/Local/Temp/ray/session_2025-02-02_13-43-52_377343_24792/artifacts/2025-02-02_13-44-02/tune_bert/driver_artifacts\n",
      "Number of trials: 20/20 (1 ERROR, 19 PENDING)\n",
      "Number of errored trials: 1\n",
      "+------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name             |   # failures | error file                                                                                                                                                     |\n",
      "|------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| train_func_ff99a_00000 |            1 | C:/Users/Kone/AppData/Local/Temp/ray/session_2025-02-02_13-43-52_377343_24792/artifacts/2025-02-02_13-44-02/tune_bert/driver_artifacts/t_ff99a_00000/error.txt |\n",
      "+------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_func pid=30712)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[36m(train_func pid=30712)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-02-02 13:44:18 (running for 00:00:15.93)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 1.0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: C:/Users/Kone/AppData/Local/Temp/ray/session_2025-02-02_13-43-52_377343_24792/artifacts/2025-02-02_13-44-02/tune_bert/driver_artifacts\n",
      "Number of trials: 20/20 (1 ERROR, 18 PENDING, 1 RUNNING)\n",
      "Number of errored trials: 1\n",
      "+------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name             |   # failures | error file                                                                                                                                                     |\n",
      "|------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| train_func_ff99a_00000 |            1 | C:/Users/Kone/AppData/Local/Temp/ray/session_2025-02-02_13-43-52_377343_24792/artifacts/2025-02-02_13-44-02/tune_bert/driver_artifacts/t_ff99a_00000/error.txt |\n",
      "+------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_func pid=30712)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "\u001b[36m(train_func pid=30712)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/2346 [00:00<?, ?it/s]\n",
      "2025-02-02 13:44:19,334\tERROR tune_controller.py:1331 -- Trial task failed for trial train_func_ff99a_00001\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2772, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\_private\\worker.py\", line 919, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=30712, ip=127.0.0.1, actor_id=3bffc4ed5b2bef344d34653e01000000, repr=train_func)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\air\\_internal\\util.py\", line 107, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 44, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\ray\\tune\\trainable\\function_trainable.py\", line 249, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"C:\\Users\\Kone\\AppData\\Local\\Temp\\ipykernel_24792\\1460561625.py\", line 118, in train_func\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\transformers\\trainer.py\", line 2171, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\transformers\\trainer.py\", line 2531, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\transformers\\trainer.py\", line 3675, in training_step\n",
      "    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\transformers\\trainer.py\", line 3752, in compute_loss\n",
      "    raise ValueError(\n",
      "ValueError: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,token_type_ids,attention_mask.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "== Status ==\n",
      "Current time: 2025-02-02 13:44:23 (running for 00:00:20.96)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 1.0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: C:/Users/Kone/AppData/Local/Temp/ray/session_2025-02-02_13-43-52_377343_24792/artifacts/2025-02-02_13-44-02/tune_bert/driver_artifacts\n",
      "Number of trials: 20/20 (2 ERROR, 18 PENDING)\n",
      "Number of errored trials: 2\n",
      "+------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name             |   # failures | error file                                                                                                                                                     |\n",
      "|------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| train_func_ff99a_00000 |            1 | C:/Users/Kone/AppData/Local/Temp/ray/session_2025-02-02_13-43-52_377343_24792/artifacts/2025-02-02_13-44-02/tune_bert/driver_artifacts/t_ff99a_00000/error.txt |\n",
      "| train_func_ff99a_00001 |            1 | C:/Users/Kone/AppData/Local/Temp/ray/session_2025-02-02_13-43-52_377343_24792/artifacts/2025-02-02_13-44-02/tune_bert/driver_artifacts/t_ff99a_00001/error.txt |\n",
      "+------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 13:44:24,824\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2025-02-02 13:44:24,832\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/ray_temp/tune_bert' in 0.0080s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-02-02 13:44:24 (running for 00:00:22.50)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 1.0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: C:/Users/Kone/AppData/Local/Temp/ray/session_2025-02-02_13-43-52_377343_24792/artifacts/2025-02-02_13-44-02/tune_bert/driver_artifacts\n",
      "Number of trials: 20/20 (2 ERROR, 18 PENDING)\n",
      "+------------------------+----------+-----------------+-----------+-----------------+------------------------+------------------------+----------------+\n",
      "| Trial name             | status   | loc             |   dropout |   learning_rate |   per_device_eval_batc |   per_device_train_bat |   warmup_steps |\n",
      "|                        |          |                 |           |                 |                 h_size |                ch_size |                |\n",
      "|------------------------+----------+-----------------+-----------+-----------------+------------------------+------------------------+----------------|\n",
      "| train_func_ff99a_00002 | PENDING  |                 |  0.247547 |     0.000599709 |                     16 |                     32 |            200 |\n",
      "| train_func_ff99a_00003 | PENDING  |                 |  0.479233 |     0.00041334  |                     64 |                     16 |            100 |\n",
      "| train_func_ff99a_00004 | PENDING  |                 |  0.239739 |     6.30231e-05 |                     64 |                     64 |            200 |\n",
      "| train_func_ff99a_00005 | PENDING  |                 |  0.363338 |     8.53142e-05 |                     64 |                     32 |            100 |\n",
      "| train_func_ff99a_00006 | PENDING  |                 |  0.215866 |     0.000724813 |                     16 |                     32 |            300 |\n",
      "| train_func_ff99a_00007 | PENDING  |                 |  0.453109 |     1.15668e-05 |                     32 |                     32 |            300 |\n",
      "| train_func_ff99a_00008 | PENDING  |                 |  0.314886 |     0.000505451 |                     16 |                     32 |            200 |\n",
      "| train_func_ff99a_00009 | PENDING  |                 |  0.241999 |     1.06947e-05 |                     64 |                     32 |            100 |\n",
      "| train_func_ff99a_00010 | PENDING  |                 |  0.343314 |     3.46305e-05 |                     16 |                     32 |            200 |\n",
      "| train_func_ff99a_00011 | PENDING  |                 |  0.399949 |     1.7406e-05  |                     64 |                     64 |            300 |\n",
      "| train_func_ff99a_00012 | PENDING  |                 |  0.184674 |     2.82739e-05 |                     32 |                     16 |            300 |\n",
      "| train_func_ff99a_00013 | PENDING  |                 |  0.243599 |     8.94372e-05 |                     32 |                     16 |            100 |\n",
      "| train_func_ff99a_00014 | PENDING  |                 |  0.375933 |     0.000283933 |                     64 |                     64 |            100 |\n",
      "| train_func_ff99a_00015 | PENDING  |                 |  0.129814 |     6.81247e-05 |                     64 |                     32 |            100 |\n",
      "| train_func_ff99a_00016 | PENDING  |                 |  0.250529 |     9.97545e-05 |                     32 |                     64 |            100 |\n",
      "| train_func_ff99a_00017 | PENDING  |                 |  0.238394 |     3.29357e-05 |                     64 |                     64 |            100 |\n",
      "| train_func_ff99a_00018 | PENDING  |                 |  0.212701 |     1.51936e-05 |                     16 |                     16 |            300 |\n",
      "| train_func_ff99a_00019 | PENDING  |                 |  0.390899 |     3.96166e-05 |                     64 |                     64 |            100 |\n",
      "| train_func_ff99a_00000 | ERROR    | 127.0.0.1:25824 |  0.416006 |     3.16214e-05 |                     64 |                     16 |            300 |\n",
      "| train_func_ff99a_00001 | ERROR    | 127.0.0.1:30712 |  0.201237 |     2.59065e-05 |                     16 |                     32 |            100 |\n",
      "+------------------------+----------+-----------------+-----------+-----------------+------------------------+------------------------+----------------+\n",
      "Number of errored trials: 2\n",
      "+------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name             |   # failures | error file                                                                                                                                                     |\n",
      "|------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| train_func_ff99a_00000 |            1 | C:/Users/Kone/AppData/Local/Temp/ray/session_2025-02-02_13-43-52_377343_24792/artifacts/2025-02-02_13-44-02/tune_bert/driver_artifacts/t_ff99a_00000/error.txt |\n",
      "| train_func_ff99a_00001 |            1 | C:/Users/Kone/AppData/Local/Temp/ray/session_2025-02-02_13-43-52_377343_24792/artifacts/2025-02-02_13-44-02/tune_bert/driver_artifacts/t_ff99a_00001/error.txt |\n",
      "+------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 13:44:25,851\tERROR tune.py:1037 -- Trials did not complete: [train_func_ff99a_00000, train_func_ff99a_00001]\n",
      "2025-02-02 13:44:25,852\tINFO tune.py:1041 -- Total run time: 23.52 seconds (22.49 seconds for the tuning loop).\n",
      "2025-02-02 13:44:25,852\tWARNING tune.py:1056 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: tune.run(..., resume=True)\n",
      "2025-02-02 13:44:25,862\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 18 trial(s):\n",
      "- train_func_ff99a_00002: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00002: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00002')\n",
      "- train_func_ff99a_00003: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00003: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00003')\n",
      "- train_func_ff99a_00004: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00004: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00004')\n",
      "- train_func_ff99a_00005: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00005: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00005')\n",
      "- train_func_ff99a_00006: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00006: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00006')\n",
      "- train_func_ff99a_00007: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00007: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00007')\n",
      "- train_func_ff99a_00008: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00008: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00008')\n",
      "- train_func_ff99a_00009: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00009: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00009')\n",
      "- train_func_ff99a_00010: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00010: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00010')\n",
      "- train_func_ff99a_00011: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00011: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00011')\n",
      "- train_func_ff99a_00012: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00012: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00012')\n",
      "- train_func_ff99a_00013: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00013: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00013')\n",
      "- train_func_ff99a_00014: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00014: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00014')\n",
      "- train_func_ff99a_00015: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00015: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00015')\n",
      "- train_func_ff99a_00016: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00016: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00016')\n",
      "- train_func_ff99a_00017: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00017: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00017')\n",
      "- train_func_ff99a_00018: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00018: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00018')\n",
      "- train_func_ff99a_00019: FileNotFoundError('Could not fetch metrics for train_func_ff99a_00019: both result.json and progress.csv were not found at C:/ray_temp/tune_bert/t_ff99a_00019')\n",
      "2025-02-02 13:44:25,862\tWARNING experiment_analysis.py:558 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24792\\1460561625.py:150\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# Run hyperparameter optimization\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting hyperparameter optimization...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 150\u001b[0m best_config \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_with_ray_tune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# Save best configuration\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24792\\1460561625.py:143\u001b[0m, in \u001b[0;36mtrain_with_ray_tune\u001b[1;34m(num_trials)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Get best trial\u001b[39;00m\n\u001b[0;32m    142\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m analysis\u001b[38;5;241m.\u001b[39mget_best_trial(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial config:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mbest_trial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial final accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_trial\u001b[38;5;241m.\u001b[39mlast_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_trial\u001b[38;5;241m.\u001b[39mconfig\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "# Categorimport os\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Dict\n",
    "\n",
    "# Get the directory where the notebook is located\n",
    "notebook_dir = os.path.dirname(os.path.abspath('C:/Users/Kone/ftllm/wk02/ex02.ipynb'))\n",
    "\n",
    "# Create paths relative to the notebook directory\n",
    "results_dir = os.path.join(notebook_dir, 'ray_tune_results')\n",
    "logs_dir = os.path.join(notebook_dir, 'ray_logs')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Initialize ray\n",
    "ray.shutdown()\n",
    "ray.init(num_gpus=1)\n",
    "print(ray.cluster_resources())\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "class TuneTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._report_to_ray_metrics = True\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
    "        if self._report_to_ray_metrics:\n",
    "            self._report_to_ray(metrics, state.global_step)\n",
    "        return super().on_evaluate(args, state, control, metrics, **kwargs)\n",
    "\n",
    "def model_init():\n",
    "    \"\"\"Initialize a new model for each trial\"\"\"\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-uncased\",\n",
    "        num_labels=2\n",
    "    )\n",
    "\n",
    "def hp_space(trial):\n",
    "    \"\"\"Define the hyperparameter search space\"\"\"\n",
    "    return {\n",
    "        \"learning_rate\": tune.loguniform(1e-5, 1e-3),\n",
    "        \"per_device_train_batch_size\": tune.choice([16, 32, 64]),\n",
    "        \"per_device_eval_batch_size\": tune.choice([16, 32, 64]),\n",
    "        \"num_train_epochs\": 3,\n",
    "        \"warmup_steps\": tune.choice([100, 200, 300]),\n",
    "        \"dropout\": tune.uniform(0.1, 0.5)\n",
    "    }\n",
    "\n",
    "def train_with_ray_tune(num_trials=20):\n",
    "    # Load dataset (using IMDB for example)\n",
    "    dataset = load_dataset(\"imdb\")\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    \n",
    "    # Tokenize function\n",
    "    def tokenize_function(examples):\n",
    "        # Preserve the label information\n",
    "        encoding = tokenizer(\n",
    "            examples[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        )\n",
    "        encoding[\"labels\"] = examples[\"label\"]  # Retain the labels\n",
    "        return encoding\n",
    "    \n",
    "    # Prepare dataset\n",
    "    tokenized_datasets = dataset.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=[\"text\"]\n",
    "    )\n",
    "    \n",
    "    # Define training arguments template\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=results_dir,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=500,\n",
    "        save_strategy=\"no\",\n",
    "        logging_dir=logs_dir,\n",
    "    )\n",
    "    \n",
    "    # Define ASHA scheduler\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=3,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2,\n",
    "        brackets=1,\n",
    "    )\n",
    "    \n",
    "    def train_func(config):\n",
    "        # Update training arguments with trial config\n",
    "        for key, value in config.items():\n",
    "            if hasattr(training_args, key):\n",
    "                setattr(training_args, key, value)\n",
    "        \n",
    "        # Initialize trainer\n",
    "        trainer = TuneTrainer(\n",
    "            model_init=model_init,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_datasets[\"train\"],\n",
    "            eval_dataset=tokenized_datasets[\"test\"],\n",
    "        )\n",
    "        \n",
    "        # Train and evaluate\n",
    "        trainer.train()\n",
    "    \n",
    "    # Define a shorter trial directory name creator\n",
    "    def trial_name_creator(trial):\n",
    "        return f\"t_{trial.trial_id}\"\n",
    "\n",
    "    analysis = tune.run(\n",
    "        train_func,\n",
    "        config=hp_space(None),\n",
    "        storage_path=\"C:/ray_temp\",\n",
    "        trial_dirname_creator=trial_name_creator,\n",
    "        name=\"tune_bert\",\n",
    "        num_samples=num_trials,\n",
    "        scheduler=scheduler,\n",
    "        metric=\"accuracy\",\n",
    "        mode=\"max\",\n",
    "        resources_per_trial={\n",
    "            \"cpu\": 1,\n",
    "            \"gpu\": 1 if torch.cuda.is_available() else 0\n",
    "        },\n",
    "        progress_reporter=tune.CLIReporter()\n",
    "    )\n",
    "    \n",
    "    # Get best trial\n",
    "    best_trial = analysis.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "    print(\"Best trial config:\", best_trial.config)\n",
    "    print(\"Best trial final accuracy:\", best_trial.last_result[\"accuracy\"])\n",
    "    \n",
    "    return best_trial.config\n",
    "\n",
    "# Run hyperparameter optimization\n",
    "print(\"Starting hyperparameter optimization...\")\n",
    "best_config = train_with_ray_tune(num_trials=20)\n",
    "\n",
    "# Save best configuration\n",
    "import json\n",
    "with open(\"best_hyperparameters.json\", \"w\") as f:\n",
    "    json.dump(best_config, f)\n",
    "\n",
    "print(\"\\nHyperparameter optimization complete!\")\n",
    "print(\"Best configuration saved to best_hyperparameters.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ray_tune_init'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24792\\576002651.py:95\u001b[0m\n\u001b[0;32m     92\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mcleanup()\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24792\\576002651.py:70\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Example usage of the optimization pipeline.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mray_tune_init\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TransformerOptimizer, OptimizationConfig\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# Initialize with custom config if needed\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     config \u001b[38;5;241m=\u001b[39m OptimizationConfig(\n\u001b[0;32m     74\u001b[0m         model_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     75\u001b[0m         num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m         gpus_per_trial\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     79\u001b[0m     )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ray_tune_init'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
