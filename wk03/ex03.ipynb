{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: Dataset Preparation and Fine-Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Download the IMDB Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (50000, 2)\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n",
      "None\n",
      "\n",
      "First few rows of the dataset:\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "\n",
      "Missing values in each column:\n",
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "positive    25000\n",
      "negative    25000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset loaded successfully!\n",
      "\n",
      "Sample positive review:\n",
      "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me abo...\n",
      "\n",
      "Sample negative review:\n",
      "Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, J...\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "def load_imdb_dataset(filepath='C:/Users/Kone/Downloads/archive/IMDB Dataset.csv'):\n",
    "    \"\"\"Load the IMDB dataset and perform initial verification\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Display basic information about the dataset\n",
    "    print(\"Dataset Shape:\", df.shape)\n",
    "    print(\"\\nDataset Info:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nFirst few rows of the dataset:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nMissing values in each column:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\nSentiment distribution:\")\n",
    "    print(df['sentiment'].value_counts())\n",
    "    \n",
    "    # Create a distribution plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(x='sentiment', data=df)\n",
    "    plt.title('Distribution of Sentiments in IMDB Dataset')\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the dataset\n",
    "df = load_imdb_dataset()\n",
    "print(\"\\nDataset loaded successfully!\")\n",
    "\n",
    "# Display sample reviews\n",
    "print(\"\\nSample positive review:\")\n",
    "print(df[df['sentiment'] == 'positive']['review'].iloc[0][:200] + \"...\")\n",
    "print(\"\\nSample negative review:\")\n",
    "print(df[df['sentiment'] == 'negative']['review'].iloc[0][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset splits:\n",
      "Training set: 40000 samples\n",
      "Validation set: 5000 samples\n",
      "Test set: 5000 samples\n",
      "\n",
      "Preprocessing completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kone\\AppData\\Local\\Temp\\ipykernel_37964\\3489028217.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review'] = df['review'].apply(lambda x: x.strip().lower())\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the IMDB dataset\"\"\"\n",
    "    # Encode sentiment labels (positive -> 1, negative -> 0)\n",
    "    df['label'] = (df['sentiment'] == 'positive').astype(int)\n",
    "    df = df[['review', 'label']]\n",
    "    \n",
    "    # Basic text cleaning\n",
    "    df['review'] = df['review'].apply(lambda x: x.strip().lower())\n",
    "    df = df[df['review'].str.len() > 0].reset_index(drop=True)\n",
    "    \n",
    "    # Split into training (80%), validation (10%), and test (10%) sets\n",
    "    train_df, temp_df = train_test_split(\n",
    "        df, test_size=0.2, random_state=42, stratify=df['label']\n",
    "    )\n",
    "    \n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df, test_size=0.5, random_state=42, stratify=temp_df['label']\n",
    "    )\n",
    "    \n",
    "    # Reset indices\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    val_df = val_df.reset_index(drop=True)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\nDataset splits:\")\n",
    "    print(f\"Training set: {len(train_df)} samples\")\n",
    "    print(f\"Validation set: {len(val_df)} samples\")\n",
    "    print(f\"Test set: {len(test_df)} samples\")\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "# Apply preprocessing\n",
    "train_df, val_df, test_df = preprocess_data(df)\n",
    "print(\"\\nPreprocessing completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Model Selection and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer: distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully!\n",
      "\n",
      "Datasets created successfully!\n",
      "Training samples: 40000\n",
      "Validation samples: 5000\n",
      "Test samples: 5000\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Constants\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for IMDB reviews\"\"\"\n",
    "    def __init__(self, reviews, labels, tokenizer, max_length):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        review = str(self.reviews[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,            # As per requirements\n",
    "            padding='max_length',       # As per requirements\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Initialize model and tokenizer\n",
    "print(f\"Loading model and tokenizer: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2,\n",
    "    return_dict=True\n",
    ")\n",
    "print(\"Model and tokenizer loaded successfully!\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = IMDBDataset(train_df['review'].values, train_df['label'].values, tokenizer, MAX_LENGTH)\n",
    "val_dataset = IMDBDataset(val_df['review'].values, val_df['label'].values, tokenizer, MAX_LENGTH)\n",
    "test_dataset = IMDBDataset(test_df['review'].values, test_df['label'].values, tokenizer, MAX_LENGTH)\n",
    "\n",
    "print(f\"\\nDatasets created successfully!\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Fine-Tune the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kone\\AppData\\Local\\Temp\\ipykernel_37964\\1383693292.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-04 18:59:28,916] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0204 18:59:29.656000 37964 Lib\\site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2500/2500 05:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.226612</td>\n",
       "      <td>0.908800</td>\n",
       "      <td>0.883346</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>0.911731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.216756</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>0.918311</td>\n",
       "      <td>0.930800</td>\n",
       "      <td>0.924513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Evaluation Metrics:\n",
      "Accuracy: 0.9240\n",
      "Precision: 0.9183\n",
      "Recall: 0.9308\n",
      "F1 Score: 0.9245\n",
      "\n",
      "Model and metrics saved to ./results\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute metrics for evaluation\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='binary'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=2,                      # As per requirements\n",
    "    per_device_train_batch_size=32,          # As per requirements (16 or 32)\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"epoch\",             # Evaluate at end of each epoch\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,                      # As per requirements\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    report_to=\"none\"                         # Disable wandb reporting\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting model training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate and print final metrics\n",
    "final_metrics = trainer.evaluate()\n",
    "print(\"\\nFinal Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {final_metrics['eval_accuracy']:.4f}\")\n",
    "print(f\"Precision: {final_metrics['eval_precision']:.4f}\")\n",
    "print(f\"Recall: {final_metrics['eval_recall']:.4f}\")\n",
    "print(f\"F1 Score: {final_metrics['eval_f1']:.4f}\")\n",
    "\n",
    "# Save final model and metrics\n",
    "trainer.save_model(\"./results\")\n",
    "metrics_path = os.path.join(\"./results\", \"training_metrics.txt\")\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    for key, value in final_metrics.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "print(f\"\\nModel and metrics saved to ./results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Save and Upload the Model to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model and tokenizer locally...\n",
      "Model and tokenizer saved to ./final_model\n",
      "\n",
      "Please login to Hugging Face (a browser window will open)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31a0eee0c06415ca34e77bcedd77653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading model to Hugging Face Hub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully uploaded to Hugging Face Hub!\n",
      "You can find the model at: https://huggingface.co/Etwo02/imdb-sentiment-classifier\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "import os\n",
    "\n",
    "# 1. Save model and tokenizer locally\n",
    "output_dir = \"./final_model\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model and tokenizer locally...\")\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Model and tokenizer saved to {output_dir}\")\n",
    "\n",
    "# 2. Login to Hugging Face\n",
    "print(\"\\nPlease login to Hugging Face (a browser window will open)...\")\n",
    "notebook_login()\n",
    "\n",
    "# 3. Push model to hub\n",
    "repo_name = \"Etwo02/imdb-sentiment-classifier\"  # You can change this name\n",
    "try:\n",
    "    print(f\"\\nUploading model to Hugging Face Hub...\")\n",
    "    model.push_to_hub(repo_name)\n",
    "    tokenizer.push_to_hub(repo_name)\n",
    "    print(f\"Model successfully uploaded to Hugging Face Hub!\")\n",
    "    print(f\"You can find the model at: https://huggingface.co/{repo_name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error uploading model: {str(e)}\")\n",
    "    print(\"Please make sure you're logged in and have the correct permissions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Link to model https://huggingface.co/Etwo02/imdb-sentiment-classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2: API Development and Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Set Up the Backend API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [37964]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:64198 - \"GET / HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64218 - \"POST /predict/?text=sad HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64218 - \"POST /predict/?text=sad HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64242 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64242 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64243 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64243 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64244 - \"POST /analyze/ HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64244 - \"POST /analyze/ HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64279 - \"POST /analyze/ HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64279 - \"POST /analyze/ HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64280 - \"POST /analyze/ HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [37964]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 156\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mServer started\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 156\u001b[0m     \u001b[43mrun_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 144\u001b[0m, in \u001b[0;36mrun_server\u001b[1;34m()\u001b[0m\n\u001b[0;32m    142\u001b[0m config \u001b[38;5;241m=\u001b[39m uvicorn\u001b[38;5;241m.\u001b[39mConfig(app, host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.0.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, port\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8000\u001b[39m, log_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    143\u001b[0m server \u001b[38;5;241m=\u001b[39m uvicorn\u001b[38;5;241m.\u001b[39mServer(config)\n\u001b[1;32m--> 144\u001b[0m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\uvicorn\\server.py:66\u001b[0m, in \u001b[0;36mServer.run\u001b[1;34m(self, sockets)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket\u001b[38;5;241m.\u001b[39msocket] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msetup_event_loop()\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[1;32mc:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\nest_asyncio.py:133\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    130\u001b[0m curr_task \u001b[38;5;241m=\u001b[39m curr_tasks\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 133\u001b[0m     \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# restore the current task\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m curr_task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py:88\u001b[0m, in \u001b[0;36mHandle._run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:396\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;66;03m# Don't pass the value of `future.result()` explicitly,\u001b[39;00m\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;66;03m# as `Future.__iter__` and `Future.__await__` don't need it.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;66;03m# instead of `__next__()`, which is slower for futures\u001b[39;00m\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;66;03m# that return non-generator iterators from their `__iter__`.\u001b[39;00m\n\u001b[1;32m--> 396\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:303\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(self, exc)\u001b[0m\n\u001b[0;32m    301\u001b[0m _enter_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 303\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__step_run_and_handle_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m     _leave_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:314\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 314\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[1;32mc:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\uvicorn\\server.py:69\u001b[0m, in \u001b[0;36mServer.serve\u001b[1;34m(self, sockets)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mserve\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket\u001b[38;5;241m.\u001b[39msocket] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapture_signals\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mawait\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kone\\ftllm\\yes\\Lib\\site-packages\\uvicorn\\server.py:330\u001b[0m, in \u001b[0;36mServer.capture_signals\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;66;03m# If we did gracefully shut down due to a signal, try to\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;66;03m# trigger the expected behaviour now; multiple signals would be\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# done LIFO, see https://stackoverflow.com/questions/48434964\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m captured_signal \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_captured_signals):\n\u001b[1;32m--> 330\u001b[0m     \u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_signal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaptured_signal\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "# main.py\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Literal\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import httpx\n",
    "import json\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "\n",
    "# Apply nest_asyncio to allow running async code in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"Sentiment Analysis API\",\n",
    "    description=\"API for analyzing sentiment using custom DistilBERT and Llama 3 models\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Model paths and configs\n",
    "MODEL_PATH = \"./final_model\"  # Update with your model path\n",
    "TOKENIZER_PATH = \"./tokenizer_config\"  # Update with your tokenizer path\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "# Initialize custom model and tokenizer\n",
    "custom_tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "custom_model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "custom_model.eval()\n",
    "\n",
    "# Groq API configuration\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "GROQ_API_URL = \"https://api.groq.com/v1/completions\"\n",
    "\n",
    "class SentimentRequest(BaseModel):\n",
    "    text: str\n",
    "    model: Literal[\"custom\", \"llama\"]\n",
    "\n",
    "class SentimentResponse(BaseModel):\n",
    "    sentiment: str\n",
    "    confidence: float\n",
    "\n",
    "def analyze_with_custom_model(text: str) -> tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Analyze sentiment using the custom fine-tuned model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Tokenize input\n",
    "        inputs = custom_tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=MAX_LENGTH,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Get model prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = custom_model(**inputs)\n",
    "            probabilities = F.softmax(outputs.logits, dim=1)\n",
    "            prediction = torch.argmax(probabilities, dim=1)\n",
    "            confidence = torch.max(probabilities).item()\n",
    "\n",
    "        # Convert prediction to sentiment\n",
    "        sentiment = \"positive\" if prediction.item() == 1 else \"negative\"\n",
    "        \n",
    "        return sentiment, confidence\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Custom model error: {str(e)}\")\n",
    "\n",
    "async def analyze_with_llama(text: str) -> tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Analyze sentiment using Llama 3 via Groq API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        prompt = f\"\"\"Analyze the sentiment of the following text and respond with a JSON object containing two fields:\n",
    "        1. \"sentiment\": either \"positive\" or \"negative\"\n",
    "        2. \"confidence\": a float between 0 and 1 indicating your confidence\n",
    "\n",
    "        Text: \"{text}\"\n",
    "\n",
    "        Respond only with the JSON object.\"\"\"\n",
    "\n",
    "        payload = {\n",
    "            \"model\": \"llama2-70b-4096\",  # or your chosen Llama 3 model\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a sentiment analysis expert.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"temperature\": 0.1,\n",
    "            \"max_tokens\": 100\n",
    "        }\n",
    "\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.post(GROQ_API_URL, headers=headers, json=payload)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Parse the response\n",
    "            result = response.json()\n",
    "            content = result['choices'][0]['message']['content']\n",
    "            parsed_result = json.loads(content)\n",
    "            \n",
    "            return parsed_result[\"sentiment\"], float(parsed_result[\"confidence\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Llama model error: {str(e)}\")\n",
    "\n",
    "@app.post(\"/analyze/\", response_model=SentimentResponse)\n",
    "async def analyze_sentiment(request: SentimentRequest):\n",
    "    \"\"\"\n",
    "    Analyze the sentiment of input text using either custom or Llama model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if request.model == \"custom\":\n",
    "            sentiment, confidence = analyze_with_custom_model(request.text)\n",
    "        else:  # llama\n",
    "            sentiment, confidence = await analyze_with_llama(request.text)\n",
    "\n",
    "        return SentimentResponse(\n",
    "            sentiment=sentiment,\n",
    "            confidence=confidence\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "def run_server():\n",
    "    \"\"\"Function to run the server\"\"\"\n",
    "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
    "    server = uvicorn.Server(config)\n",
    "    server.run()\n",
    "\n",
    "# For Jupyter Notebook\n",
    "def start_server():\n",
    "    \"\"\"Function to start the server in a notebook\"\"\"\n",
    "    import asyncio\n",
    "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
    "    server = uvicorn.Server(config)\n",
    "    asyncio.create_task(server.serve())\n",
    "    return \"Server started\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_loader.py\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import httpx\n",
    "import json\n",
    "from typing import Tuple, Optional\n",
    "import asyncio\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class ModelLoader:\n",
    "    def __init__(self):\n",
    "        # Environment variables\n",
    "        self.hf_token = os.getenv(\"HUGGING_FACE_TOKEN\")\n",
    "        self.groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "        self.model_id = os.getenv(\"HF_MODEL_ID\", \"your-username/your-model-name\")  # Update with your model ID\n",
    "        \n",
    "        # Model configurations\n",
    "        self.custom_model = None\n",
    "        self.custom_tokenizer = None\n",
    "        self.max_length = 256\n",
    "        \n",
    "        # Groq API configuration\n",
    "        self.groq_api_url = \"https://api.groq.com/v1/chat/completions\"\n",
    "        self.groq_model = \"mixtral-8x7b-32768\"  # or your chosen Llama model\n",
    "        \n",
    "    def load_custom_model(self) -> Tuple[Optional[AutoModelForSequenceClassification], Optional[AutoTokenizer]]:\n",
    "        \"\"\"\n",
    "        Load the fine-tuned model from Hugging Face\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"Loading custom model from Hugging Face...\")\n",
    "            \n",
    "            # Login to Hugging Face\n",
    "            if self.hf_token:\n",
    "                login(self.hf_token)\n",
    "            \n",
    "            # Load tokenizer and model\n",
    "            self.custom_tokenizer = AutoTokenizer.from_pretrained(self.model_id)\n",
    "            self.custom_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                self.model_id,\n",
    "                num_labels=2  # Binary classification\n",
    "            )\n",
    "            \n",
    "            # Set model to evaluation mode\n",
    "            self.custom_model.eval()\n",
    "            \n",
    "            print(\"Custom model loaded successfully!\")\n",
    "            return self.custom_model, self.custom_tokenizer\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading custom model: {str(e)}\")\n",
    "            return None, None\n",
    "    \n",
    "    async def test_groq_connection(self) -> bool:\n",
    "        \"\"\"\n",
    "        Test connection to Groq API\n",
    "        \"\"\"\n",
    "        if not self.groq_api_key:\n",
    "            print(\"Groq API key not found in environment variables\")\n",
    "            return False\n",
    "            \n",
    "        try:\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {self.groq_api_key}\",\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "            \n",
    "            # Simple test prompt\n",
    "            payload = {\n",
    "                \"model\": self.groq_model,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": \"Hello, are you there?\"}\n",
    "                ],\n",
    "                \"temperature\": 0.1,\n",
    "                \"max_tokens\": 50\n",
    "            }\n",
    "            \n",
    "            async with httpx.AsyncClient() as client:\n",
    "                response = await client.post(\n",
    "                    self.groq_api_url,\n",
    "                    headers=headers,\n",
    "                    json=payload,\n",
    "                    timeout=10.0\n",
    "                )\n",
    "                response.raise_for_status()\n",
    "                \n",
    "            print(\"Groq API connection successful!\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error testing Groq API connection: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def get_groq_prompt(self, text: str) -> dict:\n",
    "        \"\"\"\n",
    "        Generate the prompt for Groq API\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"model\": self.groq_model,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a sentiment analysis expert. Analyze the sentiment of the given text and respond with a JSON object containing 'sentiment' (either 'positive' or 'negative') and 'confidence' (a float between 0 and 1).\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Analyze the sentiment of this text: '{text}'\"\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": 0.1,\n",
    "            \"max_tokens\": 100\n",
    "        }\n",
    "\n",
    "# Usage example\n",
    "async def initialize_models():\n",
    "    \"\"\"\n",
    "    Initialize and test both models\n",
    "    \"\"\"\n",
    "    # Create model loader instance\n",
    "    loader = ModelLoader()\n",
    "    \n",
    "    # Load custom model\n",
    "    custom_model, custom_tokenizer = loader.load_custom_model()\n",
    "    if custom_model is None or custom_tokenizer is None:\n",
    "        print(\"Failed to load custom model\")\n",
    "    \n",
    "    # Test Groq API connection\n",
    "    groq_connection = await loader.test_groq_connection()\n",
    "    if not groq_connection:\n",
    "        print(\"Failed to connect to Groq API\")\n",
    "    \n",
    "    return loader, custom_model, custom_tokenizer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create .env file template if it doesn't exist\n",
    "    if not os.path.exists(\".env\"):\n",
    "        with open(\".env\", \"w\") as f:\n",
    "            f.write(\"\"\"# Hugging Face token\n",
    "HUGGING_FACE_TOKEN=your_token_here\n",
    "# Groq API key\n",
    "GROQ_API_KEY=your_groq_api_key_here\n",
    "# Your fine-tuned model ID on Hugging Face\n",
    "HF_MODEL_ID=your-username/your-model-name\n",
    "\"\"\")\n",
    "        print(\"Created .env template file. Please fill in your credentials.\")\n",
    "    \n",
    "    # Run initialization\n",
    "    asyncio.run(initialize_models())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
